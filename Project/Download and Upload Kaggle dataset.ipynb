{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65968c99",
   "metadata": {},
   "source": [
    "## Download from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da913627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install library\n",
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d483b009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T17:43:53.696640Z",
     "start_time": "2022-03-03T17:43:53.480372Z"
    }
   },
   "outputs": [],
   "source": [
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e44c3a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T16:11:38.201510Z",
     "start_time": "2022-02-24T13:54:17.314226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: paulineguevara\n",
      "Your Kaggle Key: ········\n",
      "Downloading medical-masks-part1.zip to ./medical-masks-part1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80.4G/80.4G [1:44:15<00:00, 13.8MB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download from kaggle to jojie\n",
    "od.download('https://www.kaggle.com/tapakah68/medical-masks-part1?select=images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dade480",
   "metadata": {},
   "source": [
    "## Upload to AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b07e0",
   "metadata": {},
   "source": [
    "### Option 1: Zip and upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f04260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip folder\n",
    "!zip -r filename.zip folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d84c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload in AWS\n",
    "!aws s3 cp filename.zip s3://<your s3 bucket name>   # e.g. calis-bdcc2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e521b50",
   "metadata": {},
   "source": [
    "### Option 2: Upload folder to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03cea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import argv\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "ACCESS_KEY = ''  # personal access key\n",
    "SECRET_KEY = ''  # personal secret access key\n",
    "bucket_name = ''  # s3 bucket name\n",
    "\n",
    "s3_folder = 'mask_project'  # name of folder you want to save it to in your s3\n",
    "walks = os.walk('medical-masks-part1')  # folder where it is saved in Jojie\n",
    "\n",
    "def upload_to_aws(bucket, local_file, s3_file):\n",
    "    \"\"\"Function to upload to s3.\n",
    "    \n",
    "    local_file, s3_file can be paths\"\"\"\n",
    "    \n",
    "    s3 = boto3.client('s3', aws_access_key_id=ACCESS_KEY,\n",
    "                      aws_secret_access_key=SECRET_KEY)\n",
    "    print('  Uploading ' +local_file + ' as ' + bucket + '/' +s3_file)\n",
    "    try:\n",
    "        s3.upload_file(local_file, bucket, s3_file)\n",
    "        print('  '+s3_file + \": Upload Successful\")\n",
    "        print('  ---------')\n",
    "        return True\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return False\n",
    "\n",
    "\"\"\"For file names\"\"\"\n",
    "for source, dirs, files in walks:\n",
    "    print('Directory: ' + source)\n",
    "    for filename in files:\n",
    "        # construct the full local path\n",
    "        local_file = os.path.join(source, filename)\n",
    "\n",
    "        # construct the full Dropbox path\n",
    "        s3_file = os.path.join(s3_folder, local_file)\n",
    "\n",
    "        # Invoke upload function\n",
    "        upload_to_aws(bucket_name, local_file, s3_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae89275d",
   "metadata": {},
   "source": [
    "## Happywhale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6023c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T17:37:51.549740Z",
     "start_time": "2022-03-03T17:37:46.773885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'YHR06PMERK0FPTEA',\n",
       "  'HostId': 'PVdwqA9UUo4nV/7ZetBSDflRD21gduCn9uoxc4KbUJw5WyrB0Y9UMiOwlbgPardDcGBqTRrhhec=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'PVdwqA9UUo4nV/7ZetBSDflRD21gduCn9uoxc4KbUJw5WyrB0Y9UMiOwlbgPardDcGBqTRrhhec=',\n",
       "   'x-amz-request-id': 'YHR06PMERK0FPTEA',\n",
       "   'date': 'Thu, 03 Mar 2022 17:37:52 GMT',\n",
       "   'x-amz-bucket-region': 'us-east-1',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'IsTruncated': False,\n",
       " 'Name': 'happywhales6ee92cd7-15f7-4c90-9465-86d1634f8e6f',\n",
       " 'Prefix': '',\n",
       " 'MaxKeys': 1000,\n",
       " 'EncodingType': 'url',\n",
       " 'KeyCount': 0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "aws_id = ''\n",
    "aws_key = ''\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_id,\n",
    "    aws_secret_access_key=aws_key,\n",
    ")\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_id,\n",
    "    aws_secret_access_key=aws_key,\n",
    ")\n",
    "bucket_name = ''.join(['happywhales', str(uuid.uuid4())])\n",
    "bucket_response = s3_client.create_bucket(Bucket=bucket_name)\n",
    "\n",
    "response = s3_client.list_buckets()\n",
    "\n",
    "# Output the bucket names\n",
    "#print('Existing buckets:')\n",
    "#for bucket in response['Buckets']:\n",
    "#    print(f'  {bucket[\"Name\"]}')\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/'):\n",
    "    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "        file_name = os.path.join(dirname, filename)\n",
    "        response = s3_client.upload_file(file_name, bucket_name, filename)\n",
    "\n",
    "# Let us get some feedback: the list of the objects of our Bucket is very verbose and we can\n",
    "# check that everything is OK\n",
    "\n",
    "s3_client.list_objects_v2(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ee871",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/c/happy-whale-and-dolphin/data?select=test_images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
